{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webScraper import *\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">\n",
    "    Step 1: Scrape Latest Articles\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape latest articles from https://nos.nl\n",
    "# Outputs latest articles in 'articles_scrapped.json'\n",
    "webDataScrape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">\n",
    "    Step 2: Add to Master Article List\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updates master_article_list.json, using articles_scrapped.json as input\n",
    "updateMasterList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check length of master article list\n",
    "master_article_list = []\n",
    "with open('master_article_list.json') as json_file:\n",
    "    master_article_data = json.load(json_file)\n",
    "    for article in master_article_data:\n",
    "        master_article_list.append(Article(article['ID'], article['url'], article['title'], article['date_time'], article['text']))\n",
    "print(len(master_article_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">\n",
    "    Step 3: Convert text in Articles to list of words with frequency\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all articles from master list\n",
    "master_article_list = []\n",
    "with open('master_article_list.json') as json_file:\n",
    "    master_article_data = json.load(json_file)\n",
    "    for article in master_article_data:\n",
    "        master_article_list.append(Article(article['ID'], article['url'], article['title'], article['date_time'], article['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve list of words from each article\n",
    "full_word_list = []\n",
    "for article in master_article_list:\n",
    "    full_word_list.extend(article.retrieveWordList())\n",
    "print(full_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts word list to dictionary containing count of each word\n",
    "word_list_count_dict = {}\n",
    "for word in full_word_list:\n",
    "    if word in word_list_count_dict.keys():\n",
    "        word_list_count_dict[word] = word_list_count_dict[word] + 1\n",
    "    else:\n",
    "        word_list_count_dict[word] = 1\n",
    "print(word_list_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Dataframe and sort\n",
    "word_count_df = pd.DataFrame(columns=['word', 'count'])\n",
    "for word, count in word_list_count_dict.items():\n",
    "    word_count_df.loc[len(word_count_df.index)] = [word, count]\n",
    "\n",
    "word_count_sorted_df = word_count_df.sort_values(by=['count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output sorted word list to csv\n",
    "word_count_sorted_df.to_csv('word_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">\n",
    "    Step 4: Remove Invalid Words and Custom Filtered Words\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove words from invalid_words.csv - These are either symbol characters, names of people etc.\n",
    "with open('invalid_words.csv', newline='') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    invalid_word_list = [element[0] for element in list(reader)]\n",
    "\n",
    "# Remove already learned words\n",
    "with open('learned_words.csv', newline='') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    learned_words_list = [element[0] for element in list(reader)]\n",
    "\n",
    "# Combine lists\n",
    "words_to_remove_list = invalid_word_list + learned_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove words from current dataframe word count list\n",
    "word_count_filtered_df = word_count_sorted_df.copy()\n",
    "for remove_word in words_to_remove_list:\n",
    "    word_count_filtered_df = word_count_filtered_df[word_count_filtered_df.word !=remove_word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output filtered word list to csv\n",
    "word_count_filtered_df.to_csv('word_list_filtered.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
